# ì‹¤í–‰ ëª…ë ¹ì–´: streamlit run web.py

import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium
import plotly.express as px


# 'ì˜ˆì¸¡api.py'ì— í•„ìš”í–ˆë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import requests
import io
import time
import datetime

# -----------------------------------------------------------------
# âœ¨ 1. 'ì˜ˆì¸¡api.py' ì½”ë“œë¥¼ í•¨ìˆ˜ë¡œ í†µí•© (1ì‹œê°„ ìºì‹œ ì ìš©)
# -----------------------------------------------------------------
@st.cache_data(ttl=3600)  # 3600ì´ˆ = 1ì‹œê°„ ë™ì•ˆ API ê²°ê³¼ ìºì‹œ(ì €ì¥)
def get_today_forecast(df_locations_for_api):
    """
    locations.csvì˜ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìƒì²­ APIë¥¼ í˜¸ì¶œí•˜ì—¬
    ì˜¤ëŠ˜ì˜ 3ì‹œê°„ ë‹¨ìœ„ ë‚ ì”¨ ì˜ˆë³´(ì¼ì‚¬, ê¸°ì˜¨, ìŠµë„)ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ìˆ˜ì •ë¨: time.sleep(0.5) ë° timeout=60 ì ìš©)
    """
    
    # --- 1. íŒŒë¼ë¯¸í„° ì„¤ì • ---
    AUTH_KEY = "vLfGjQIPTia3xo0CD94muA" # ì‚¬ìš©ì API í‚¤
    BASE_URL = "https://apihub.kma.go.kr/api/typ01/cgi-bin/url/nph_sun_nwp_txt"
    CONVERSION_FACTOR = (3 * 3600) / 1000000 
    VARIABLES_TO_FETCH = {
        "DSWRF": "ì¼ì‚¬", "TMP": "ê¸°ì˜¨", "RH": "ìŠµë„"
    }
    time_periods = [
        {"name": "Part 1", "start_time": "0000", "end_time": "1500"},
        {"name": "Part 2", "start_time": "1800", "end_time": "2100"}
    ]

    # --- 2. API ëª¨ë¸ ì‹œê°„ ì„¤ì • (ì–´ì œ 18ì‹œ UTC) ---
    try:
        TODAY = datetime.datetime.now()
        YESTERDAY = TODAY - datetime.timedelta(days=1)
        TODAY_STR = TODAY.strftime('%Y%m%d')
        YESTERDAY_STR = YESTERDAY.strftime('%Y%m%d')
        MODEL_RUN_TIME = YESTERDAY_STR + "1800"
    except Exception as e:
        print(f"ë‚ ì§œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        MODEL_RUN_TIME = (datetime.datetime.now() - datetime.timedelta(days=1)).strftime('%Y%m%d') + "1800"
        TODAY_STR = datetime.datetime.now().strftime('%Y%m%d')
        
    all_parsed_data = []

    # --- 3. API íŒŒì„œ í•¨ìˆ˜ (UTC -> KST ë³€í™˜ í¬í•¨) ---
    def parse_nwp_response(text_data, location_name, variable_name_korean):
        try:
            lines = text_data.strip().split('\n')
            table_lines = [line.strip() for line in lines if line.strip().startswith('|')]
            if len(table_lines) < 2: return None
            header_line = table_lines[0]
            headers = [h.strip() for h in header_line.split('|') if h.strip()]
            data_line = table_lines[1]
            values = [v.strip() for v in data_line.split('|') if v.strip()]
            time_headers = headers[4:]
            time_values = values[4:]
            if len(time_headers) != len(time_values): return None
            
            parsed_data = []
            for dt_str, val_str in zip(time_headers, time_values):
                try:
                    dt_utc = pd.to_datetime(dt_str, format='%Y%m%d%H').tz_localize('UTC')
                    dt_obj = dt_utc.tz_convert('Asia/Seoul') # KST
                    value = float(val_str.replace('-nan', 'NaN'))
                except ValueError:
                    continue
                    
                parsed_data.append({
                    "ë°œì „ê¸°ëª…": location_name, "DATETIME": dt_obj,
                    "ë³€ìˆ˜ëª…": variable_name_korean, "ê°’": value
                })
            return pd.DataFrame(parsed_data) if parsed_data else None
        except Exception as e:
            print(f"   -> [íŒŒì‹± í•¨ìˆ˜ ì˜¤ë¥˜] {location_name} ({variable_name_korean}): {e}")
            return None

    # --- 4. ë©”ì¸ API ìš”ì²­ ë¡œì§ ---
    print(f"--- 'ì˜¤ëŠ˜({TODAY_STR})' ì˜ˆì¸¡ ë°ì´í„° ìˆ˜ì§‘ ë° ë³€í™˜ ì‹œì‘ (ìºì‹œ ì‹¤í–‰) ---")

    try:
        for row in df_locations_for_api.itertuples():
            lat = row.ìœ„ë„
            lon = row.ê²½ë„
            location_name = row.ë°œì „ê¸°ëª….strip()
            
            print(f"--- ğŸ“'{location_name}' (ìœ„ë„:{lat}, ê²½ë„:{lon}) ì²˜ë¦¬ ì¤‘ ---")
    
            for var_code, var_name_korean in VARIABLES_TO_FETCH.items():
                for period in time_periods:
                    forecast_start_time = TODAY_STR + period['start_time']
                    forecast_end_time = TODAY_STR + period['end_time']
                    
                    params = {
                        'authKey': AUTH_KEY, 'nwp': 'KIMG', 'varn': var_code,
                        'tm': MODEL_RUN_TIME, 'tmef1': forecast_start_time,
                        'tmef2': forecast_end_time, 'int': 3, 'lat': lat, 'lon': lon
                    }
                    try:
                        # --- ğŸš€ [ìˆ˜ì •ë¨ 1] timeout=60ìœ¼ë¡œ ë³€ê²½ ---
                        response = requests.get(BASE_URL, params=params, timeout=60) 
                        
                        if response.status_code == 200:
                            data_text = response.text.strip()
                            if data_text and not data_text.startswith("#ERROR") and not data_text.startswith("<Error>"):
                                df_temp = parse_nwp_response(data_text, location_name, var_name_korean)
                                if df_temp is not None and not df_temp.empty:
                                    all_parsed_data.append(df_temp)
                            else:
                                 # --- ğŸš€ [ìˆ˜ì •ë¨ 2] APIê°€ ì—ëŸ¬(#ERROR)ë¥¼ ë³´ë‚¼ ë•Œ ---
                                 print(f"   -> [API ì‘ë‹µ ì˜¤ë¥˜] {location_name} ({var_name_korean}): {data_text}")
                        else:
                             # --- ğŸš€ [ìˆ˜ì •ë¨ 2] HTTP ìƒíƒœ ì½”ë“œê°€ 200ì´ ì•„ë‹ ë•Œ ---
                             print(f"   -> [HTTP ì˜¤ë¥˜] {location_name} ({var_name_korean}): ìƒíƒœ ì½”ë“œ {response.status_code}")
                             
                    except requests.exceptions.Timeout:
                        # --- ğŸš€ [ìˆ˜ì •ë¨ 2] 60ì´ˆê°„ ì‘ë‹µì´ ì—†ì„ ë•Œ ---
                        print(f"   -> [ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜] {location_name} ({var_name_korean}) ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ).")
                    except Exception as e:
                        print(f"   -> [ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜] {location_name} ({var_name_korean}): {e}")
                    
                    # --- ğŸš€ [ìˆ˜ì •ë¨ 3] 0.5ì´ˆ ëŒ€ê¸° ---
                    time.sleep(0.5) 
        
        # --- 5. [í•©ë³¸] ìµœì¢… ë³€í™˜ ---
        if all_parsed_data:
            print(f"\n--- âœ¨ ëª¨ë“  ìœ„ì¹˜ ë°ì´í„° ì·¨í•© ë° ìµœì¢… ë³€í™˜ ì‹œì‘ ---")
            final_df = pd.concat(all_parsed_data, ignore_index=True)
            
            final_pivot_df = final_df.pivot_table(
                index=['ë°œì „ê¸°ëª…', 'DATETIME'], columns='ë³€ìˆ˜ëª…', values='ê°’'
            ).reset_index()
            
            final_pivot_df = final_pivot_df.sort_values(by=['ë°œì „ê¸°ëª…', 'DATETIME'])
            
            final_pivot_df['ì¼ì‚¬'] = final_pivot_df['ì¼ì‚¬'].fillna(0)
            final_pivot_df['ê¸°ì˜¨'] = final_pivot_df['ê¸°ì˜¨'].fillna(0)
            final_pivot_df['ìŠµë„'] = final_pivot_df['ìŠµë„'].fillna(0)
    
            final_pivot_df['ì¼ì‚¬ëŸ‰(MJ/mÂ²)'] = final_pivot_df['ì¼ì‚¬'] * CONVERSION_FACTOR
            final_pivot_df = final_pivot_df.drop(columns=['ì¼ì‚¬'])
            
            final_pivot_df['DATETIME'] = final_pivot_df['DATETIME'].dt.tz_localize(None)
            
            final_pivot_df = final_pivot_df.rename(columns={
                'DATETIME': 'ë‚ ì§œ', 'ê¸°ì˜¨': 'ê¸°ì˜¨(Â°C)', 'ìŠµë„': 'ìŠµë„(%)'
            })
            
            df_final_output = final_pivot_df[['ë°œì „ê¸°ëª…', 'ë‚ ì§œ', 'ì¼ì‚¬ëŸ‰(MJ/mÂ²)', 'ê¸°ì˜¨(Â°C)', 'ìŠµë„(%)']]
            
            print(f"\n--- âœ¨ API í˜¸ì¶œ ë° ë°ì´í„° ë³€í™˜ ì™„ë£Œ (ìºì‹œ ì €ì¥) ---")
            
            return df_final_output

    except Exception as e:
        print(f"[ì˜¤ë¥˜] API ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return pd.DataFrame() 

    return pd.DataFrame() 

# -----------------------------------------------------------------
# âœ¨ 2. Streamlit ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸ (ê¸°ì¡´ web.py)
# -----------------------------------------------------------------

# 1. ì›¹í˜ì´ì§€ ì œëª©
st.set_page_config(layout="wide")
st.title("â˜€ï¸ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ëŒ€ì‹œë³´ë“œ â˜€ï¸")

# 2. ë°ì´í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    # (ë¡œì»¬ ì‹¤í–‰ì„ ìœ„í•´ cp949 ìœ ì§€)
    df_locations = pd.read_csv("locations.csv", encoding='cp949') 
except FileNotFoundError:
    st.error("`locations.csv` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()
except Exception as e:
    st.error(f"locations.csv ë¡œë”© ì˜¤ë¥˜: {e}.")
    st.stop()

try:
    df_generation = pd.read_csv("ë™ì„œ+ì¤‘ë¶€(ì´ìƒì¹˜ì œê±°).csv")
except FileNotFoundError:
    st.error("`ë™ì„œ+ì¤‘ë¶€(ì´ìƒì¹˜ì œê±°).csv` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()


# 3. (ì‹ ê·œ) 'ì˜¤ëŠ˜ ë‚ ì”¨ ì˜ˆë³´' ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ìºì‹œëœ í•¨ìˆ˜ í˜¸ì¶œ)
weather_data_available = False
df_current_weather = pd.DataFrame()

try:
    with st.spinner('ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì˜ˆë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ ëª‡ ë¶„ ì†Œìš”)'):
        # 1ë‹¨ê³„ì—ì„œ ë§Œë“  ìºì‹œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
        df_today_forecast = get_today_forecast(df_locations) 

    if not df_today_forecast.empty:
        # KST(í•œêµ­ í‘œì¤€ì‹œ) ê¸°ì¤€ í˜„ì¬ ì‹œê°„ (ì‹œê°„ëŒ€ ì •ë³´ ì œê±°)
        now_kst = pd.to_datetime(datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))).tz_localize(None)
        
        df_today_forecast['ë‚ ì§œ'] = pd.to_datetime(df_today_forecast['ë‚ ì§œ'])

        # 'ë‚ ì§œ'ì™€ 'now_kst'ì˜ ì‹œê°„ ì°¨ì´ ê³„ì‚°
        df_today_forecast['time_diff'] = abs(df_today_forecast['ë‚ ì§œ'] - now_kst)
        
        # 'ë°œì „ê¸°ëª…'ë³„ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ëŒ€ì˜ ë°ì´í„°(í–‰)ë§Œ ë‚¨ê¹€
        df_current_weather = df_today_forecast.loc[df_today_forecast.groupby('ë°œì „ê¸°ëª…')['time_diff'].idxmin()]
        
        # ìœ„ì¹˜ ì •ë³´(ìœ„ë„/ê²½ë„/ë°œì „ì‚¬)ë¥¼ ë‹¤ì‹œ í•©ì¹˜ê¸°
        df_current_weather = pd.merge(df_current_weather, df_locations, on='ë°œì „ê¸°ëª…')
        
        weather_data_available = True
    else:
        st.warning("ë‚ ì”¨ ì˜ˆë³´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
except Exception as e:
    st.error(f"ë‚ ì”¨ API ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# 4. ê³¼ê±° ë°œì „ëŸ‰ ë°ì´í„° ì „ì²˜ë¦¬
df_generation['ë‚ ì§œ'] = pd.to_datetime(df_generation['ë‚ ì§œ'])
df_generation['ì—°ë„'] = df_generation['ë‚ ì§œ'].dt.year
df_generation['ì›”'] = df_generation['ë‚ ì§œ'].dt.month

company_colors = {
    'í•œêµ­ë™ì„œë°œì „': 'blue',
    'í•œêµ­ì¤‘ë¶€ë°œì „': 'green',
    'í•œêµ­ë‚¨ë™ë°œì „': 'red',
}

# 5. ì‚¬ì´ë“œë°” í•„í„°
st.sidebar.title("í•„í„°")
company_list = ['ì „ì²´'] + list(df_locations['ë°œì „ì‚¬'].unique())
company = st.sidebar.selectbox(
    'ë°œì „ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:',
    company_list
)

# 6. ë³¸ë¬¸ ì§€ë„ ë„ìš°ê¸° (âœ¨ í•µì‹¬ ìˆ˜ì • âœ¨)
if company == 'ì „ì²´':
    # --- 6-1. 'ì „ì²´' ì„ íƒ ì‹œ: ë‚ ì”¨ ì§€ë„ ---
    map_center = [36.5, 127.5]
    zoom_level = 7
    m = folium.Map(location=map_center, zoom_start=zoom_level)

    if weather_data_available and not df_current_weather.empty:
        st.subheader(f"ì˜¤ëŠ˜ì˜ ë°œì „ì†Œë³„ ë‚ ì”¨ ì˜ˆë³´ (í˜„ì¬ ê¸°ì¤€)")
        
        for idx, row in df_current_weather.iterrows():
            temp = row['ê¸°ì˜¨(Â°C)']
            insolation = row['ì¼ì‚¬ëŸ‰(MJ/mÂ²)'] # 3ì‹œê°„ ëˆ„ì  ì¼ì‚¬ëŸ‰
            
            html = f"""
            <div style="font-family: 'Arial', sans-serif;
                        background-color: rgba(255, 255, 255, 0.85); 
                        border: 1px solid #777; 
                        border-radius: 5px; 
                        padding: 5px 8px; 
                        font-size: 11px; 
                        text-align: center;
                        box-shadow: 2px 2px 5px rgba(0,0,0,0.3);
                        width: 90px;
                        white-space: nowrap;
                        overflow: hidden;
                        text-overflow: ellipsis;">
                <strong style="font-size: 13px; color: #333;">{row['ë°œì „ê¸°ëª…']}</strong><br>
                <span style="color: #E67E22;">â˜€ï¸ {insolation:.2f} MJ</span><br>
                <span style="color: #C0392B;">ğŸŒ¡ï¸ {temp:.1f} Â°C</span>
            </div>
            """
            
            icon = folium.features.DivIcon(
                icon_size=(100, 50), 
                icon_anchor=(50, 25), 
                html=html
            )
            
            folium.Marker(
                location=[row['ìœ„ë„'], row['ê²½ë„']],
                icon=icon,
                tooltip=f"{row['ë°œì „ê¸°ëª…']} (ë‚ ì”¨)"
            ).add_to(m)
    
    else:
        # ë‚ ì”¨ ë¡œë”© ì‹¤íŒ¨ ì‹œ
        st.subheader("ì „ì²´ ë°œì „ì†Œ ìœ„ì¹˜ (ë‚ ì”¨ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨)")
        for idx, row in df_locations.iterrows():
            folium.Marker(
                location=[row['ìœ„ë„'], row['ê²½ë„']],
                popup=row['ë°œì „ê¸°ëª…'],
                icon=folium.Icon(color='gray')
            ).add_to(m)
else:
    # --- 6-2. íŠ¹ì • ë°œì „ì‚¬ ì„ íƒ ì‹œ: ê¸°ì¡´ ë¡œì§ (ë°œì „ì†Œ ë§ˆì»¤) ---
    filtered_locations = df_locations[df_locations['ë°œì „ì‚¬'] == company]
    
    if filtered_locations.empty:
        st.warning("í•´ë‹¹ ë°œì „ì‚¬ì˜ ìœ„ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop() 
        
    map_center = [filtered_locations['ìœ„ë„'].mean(), filtered_locations['ê²½ë„'].mean()]
    zoom_level = 8
    m = folium.Map(location=map_center, zoom_start=zoom_level)

    for idx, row in filtered_locations.iterrows():
        marker_color = company_colors.get(row['ë°œì „ì‚¬'], 'gray')
        folium.Marker(
            location=[row['ìœ„ë„'], row['ê²½ë„']],
            popup=f"<strong>{row['ë°œì „ê¸°ëª…']}</strong><br>{row['ë°œì „ì‚¬']}",
            tooltip=row['ë°œì „ê¸°ëª…'],
            icon=folium.Icon(color=marker_color)
        ).add_to(m)

# 7. ì§€ë„ ì¶œë ¥
map_data = st_folium(m, width=1200, height=500)


# 8. ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
st.header(f"ğŸ“Š {company} ë°œì „ëŸ‰ ê·¸ë˜í”„")

if company == 'ì „ì²´':
    merged_data = pd.merge(df_generation, df_locations, on='ë°œì „ê¸°ëª…')
else:
    plant_names = df_locations[df_locations['ë°œì „ì‚¬'] == company]['ë°œì „ê¸°ëª…'].tolist()
    merged_data = df_generation[df_generation['ë°œì „ê¸°ëª…'].isin(plant_names)]


clicked_plant_name = map_data.get('last_object_clicked_tooltip')
graph_title_name = company

if clicked_plant_name and clicked_plant_name.endswith("(ë‚ ì”¨)"):
    st.info("ë‚ ì”¨ ë§ˆì»¤ëŠ” ë°œì „ëŸ‰ ê·¸ë˜í”„ì™€ ì—°ë™ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    clicked_plant_name = None 
elif clicked_plant_name:
    merged_data = merged_data[merged_data['ë°œì „ê¸°ëª…'] == clicked_plant_name]
    graph_title_name = clicked_plant_name
    st.subheader(f"â¡ï¸ {clicked_plant_name}")
else:
    st.subheader("ì „ì²´ ë°œì „ì†Œ í•©ê³„")

# ì‚¬ì´ë“œë°”ì— ì—°ë„/ì›” í•„í„° ì¶”ê°€
st.sidebar.title("ê¸°ê°„ í•„í„°")

year_list = ['ì „ì²´'] + sorted(list(merged_data['ì—°ë„'].unique()))
selected_year = st.sidebar.selectbox(
    'ì—°ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”:',
    year_list
)

if selected_year == 'ì „ì²´':
    month_list = ['ì „ì²´'] + sorted(list(merged_data['ì›”'].unique()))
else:
    month_list = ['ì „ì²´'] + sorted(list(merged_data[merged_data['ì—°ë„'] == selected_year]['ì›”'].unique()))

selected_month = st.sidebar.selectbox(
    'ì›”ì„ ì„ íƒí•˜ì„¸ìš”:',
    month_list
)

# ê¸°ê°„ í•„í„° ì ìš©
if selected_year != 'ì „ì²´':
    merged_data = merged_data[merged_data['ì—°ë„'] == selected_year]
if selected_month != 'ì „ì²´':
    merged_data = merged_data[merged_data['ì›”'] == selected_month]

# 9. ë³¸ë¬¸ì— ê·¸ë˜í”„ ë„ìš°ê¸°
if merged_data.empty:
    st.warning("ì„ íƒí•œ ì¡°ê±´ì˜ ë°œì „ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    daily_gen = merged_data.groupby('ë‚ ì§œ')['ë°œì „ëŸ‰(MWh)'].sum().reset_index()

    if selected_year == 'ì „ì²´' and selected_month == 'ì „ì²´':
        title_suffix = "ì „ì²´ ê¸°ê°„"
    elif selected_year != 'ì „ì²´' and selected_month == 'ì „ì²´':
        title_suffix = f"{selected_year}ë…„"
    elif selected_year != 'ì „ì²´' and selected_month != 'ì „ì²´':
        title_suffix = f"{selected_year}ë…„ {selected_month}ì›”"
    else: 
        title_suffix = f"ë§¤ë…„ {selected_month}ì›”"

    fig = px.line(daily_gen, x='ë‚ ì§œ', y='ë°œì „ëŸ‰(MWh)',
                  title=f"{graph_title_name} {title_suffix} ë°œì „ëŸ‰ í•©ê³„ ì¶”ì´",
                  markers=True)

    st.plotly_chart(fig, use_container_width=True)