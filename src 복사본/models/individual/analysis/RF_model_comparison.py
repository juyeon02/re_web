"""
ğŸŒ ëœë¤í¬ë ˆìŠ¤íŠ¸ ì„±ëŠ¥ ë¹„êµ + ì „ì²´ ë°œì „ê¸°ì— ë™ì¼ ëª¨ë¸ ìœ í˜• ì„ ì •
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â‘  ë°œì „ê¸°ë³„ Base / BE / Tuned ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
â‘¡ ê²°ê³¼(CSV/PNG) ì €ì¥
â‘¢ ì „ì²´ ë°œì „ê¸°ì˜ í‰ê·  RÂ²ì„ ë¹„êµí•´ ê°€ì¥ ìš°ìˆ˜í•œ ëª¨ë¸ ìœ í˜• ì„ íƒ
â‘£ ì„ íƒëœ ëª¨ë¸ ìœ í˜• ì •ë³´ë¥¼ CSVë¡œ ì €ì¥
"""

import os
import json
import math
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.inspection import permutation_importance

# âœ… macOS í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings("ignore", category=UserWarning)

# --------------------------------------------------
# ê²½ë¡œ ì„¤ì •
# --------------------------------------------------
BASE_DIR = "/Users/parkhyeji/Desktop/PV"
DATA_PATH = os.path.join(BASE_DIR, "data/outliers_removed/ì´ìƒì¹˜ì œê±°_ë°ì´í„°.csv")

RESULT_ROOT = os.path.join(BASE_DIR, "src/models/individual/analysis/results")
SUMMARY_DIR = os.path.join(RESULT_ROOT, "comparison")

os.makedirs(RESULT_ROOT, exist_ok=True)
os.makedirs(SUMMARY_DIR, exist_ok=True)

RANDOM_STATE = 42
TEST_SIZE = 0.2

# --------------------------------------------------
# ì‚¬ìš©í•  ë³€ìˆ˜ (9ê°œ ê³ ì •)
# --------------------------------------------------
FEATURE_COLS = [
    'ì„¤ë¹„ìš©ëŸ‰(MW)',
    'í‰ê· ê¸°ì˜¨',
    'í‰ê· ìŠµë„',
    'ì´ê°•ìˆ˜ëŸ‰',
    'ì´ì ì„¤ëŸ‰',
    'í‰ê· í’ì†',
    'ì¼ì¡°ì‹œê°„',
    'ì¼ì‚¬ëŸ‰',
    'í‰ê· ìš´ëŸ‰'
]

# --------------------------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# --------------------------------------------------
def metric_dict(y_true, y_pred):
    rmse = math.sqrt(mean_squared_error(y_true, y_pred))
    mean_y = np.mean(y_true)
    return {
        "R2": r2_score(y_true, y_pred),
        "RMSE": rmse,
        "MAE": mean_absolute_error(y_true, y_pred),
        "MAPE(%)": np.mean(np.abs((y_true - y_pred) / y_true.replace(0, np.nan))) * 100,
        "NRMSE(mean)": rmse / mean_y if mean_y != 0 else np.nan
    }

def plot_actual_vs_pred(y_true, y_pred, title, path_png):
    plt.figure(figsize=(5,5))
    plt.scatter(y_true, y_pred, s=18, alpha=0.7)
    lims = [min(np.min(y_true), np.min(y_pred)), max(np.max(y_true), np.max(y_pred))]
    plt.plot(lims, lims, color='red', lw=1)
    plt.xlabel("ì‹¤ì œ ë°œì „ëŸ‰(MWh)")
    plt.ylabel("ì˜ˆì¸¡ ë°œì „ëŸ‰(MWh)")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(path_png, dpi=150)
    plt.close()

# --------------------------------------------------
# ë°ì´í„° ë¡œë“œ
# --------------------------------------------------
print("ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...")
df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
df.columns = df.columns.str.strip()
df = df[df['ë°œì „ëŸ‰(MWh)'] != 0].copy()
print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(df)}í–‰)")

rows_summary = []

# --------------------------------------------------
# ë°œì „ê¸°ë³„ í•™ìŠµ ì‹œì‘
# --------------------------------------------------
for gen_name, group in df.groupby('ë°œì „ê¸°ëª…'):
    if len(group) < 16:
        print(f"â­ï¸ {gen_name}: ë°ì´í„° {len(group)}í–‰ (ìŠ¤í‚µ)")
        continue

    print(f"\n==============================")
    print(f"ğŸ”† ë°œì „ê¸°: {gen_name} (n={len(group)})")
    print(f"==============================")

    available_cols = [c for c in FEATURE_COLS if c in group.columns]
    if len(available_cols) == 0:
        print(f"âš ï¸ {gen_name}: ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µ")
        continue

    X = group[available_cols].fillna(0)
    y = group['ë°œì „ëŸ‰(MWh)']

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
    )

    # 1ï¸âƒ£ Base ëª¨ë¸
    base_rf = RandomForestRegressor(n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1)
    base_rf.fit(X_train, y_train)
    base_pred = base_rf.predict(X_test)
    base_m = metric_dict(y_test, base_pred)
    print(f"âœ… Base ì™„ë£Œ | RÂ²={base_m['R2']:.3f}, RMSE={base_m['RMSE']:.3f}")

    # 2ï¸âƒ£ BE (í›„ì§„ì œê±°)
    be_feats = available_cols.copy()
    best_rmse = base_m["RMSE"]
    best_model = base_rf
    step = 0
    improved = True
    while improved and len(be_feats) > 2:
        improved = False
        perm = permutation_importance(best_model, X_test[be_feats], y_test, n_repeats=5, random_state=RANDOM_STATE)
        worst = be_feats[np.argmin(perm.importances_mean)]
        trial_feats = [f for f in be_feats if f != worst]
        temp_model = RandomForestRegressor(n_estimators=500, random_state=RANDOM_STATE, n_jobs=-1)
        temp_model.fit(X_train[trial_feats], y_train)
        pred = temp_model.predict(X_test[trial_feats])
        rmse = math.sqrt(mean_squared_error(y_test, pred))
        step += 1
        if rmse < best_rmse:
            improved = True
            best_rmse = rmse
            best_model = temp_model
            be_feats = trial_feats.copy()
    be_pred = best_model.predict(X_test[be_feats])
    be_m = metric_dict(y_test, be_pred)
    print(f"ğŸ§¹ BE ì™„ë£Œ | íŠ¹ì„±ìˆ˜={len(be_feats)}, RMSE={be_m['RMSE']:.3f}")

    # 3ï¸âƒ£ Tuning (GridSearch)
    param_grid = {
        "n_estimators": [300, 600],
        "max_depth": [None, 10, 20],
        "min_samples_split": [2, 5],
        "min_samples_leaf": [1, 2],
        "max_features": [None, "sqrt", "log2"]  # âœ… 'auto' ì œê±°
    }
    cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)
    gs = GridSearchCV(
        RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),
        param_grid=param_grid,
        cv=cv, scoring="neg_root_mean_squared_error", n_jobs=-1
    )
    gs.fit(X_train, y_train)
    tuned = gs.best_estimator_
    tuned_pred = tuned.predict(X_test)
    tune_m = metric_dict(y_test, tuned_pred)
    print(f"ğŸ¯ Tuning ì™„ë£Œ | RÂ²={tune_m['R2']:.3f}, RMSE={tune_m['RMSE']:.3f}")

    # ê²°ê³¼ ì €ì¥
    rows_summary.append({
        "ë°œì „ê¸°ëª…": gen_name,
        "Base_R2": base_m["R2"], "Base_RMSE": base_m["RMSE"],
        "BE_R2": be_m["R2"], "BE_RMSE": be_m["RMSE"],
        "Tuned_R2": tune_m["R2"], "Tuned_RMSE": tune_m["RMSE"],
        "BE_ìµœì¢…íŠ¹ì„±ìˆ˜": len(be_feats),
        "BE_ìµœì¢…íŠ¹ì„±ë¦¬ìŠ¤íŠ¸": "; ".join(be_feats)
    })

# --------------------------------------------------
# ì „ì²´ ìš”ì•½ ì €ì¥
# --------------------------------------------------
summary_df = pd.DataFrame(rows_summary).sort_values("Tuned_RMSE")
summary_path = os.path.join(SUMMARY_DIR, "RF_compare_summary_by_generator.csv")
summary_df.to_csv(summary_path, index=False, encoding="utf-8-sig")
print(f"\nğŸ“Š ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {summary_path}")

# --------------------------------------------------
# ğŸŒ ì „ì²´ ë°œì „ê¸° í‰ê·  RÂ² ë¹„êµ
# --------------------------------------------------
avg_base = summary_df['Base_R2'].mean()
avg_be = summary_df['BE_R2'].mean()
avg_tuned = summary_df['Tuned_R2'].mean()

best_type, best_r2 = max(
    [('Base', avg_base), ('BE', avg_be), ('Tuned', avg_tuned)],
    key=lambda x: x[1]
)

print("\nğŸ“ˆ ëª¨ë¸ ìœ í˜•ë³„ í‰ê·  RÂ²:")
print(f"Base  : {avg_base:.4f}")
print(f"BE    : {avg_be:.4f}")
print(f"Tuned : {avg_tuned:.4f}")
print(f"\nğŸ† ì „ì²´ì ìœ¼ë¡œ ê°€ì¥ ìš°ìˆ˜í•œ ëª¨ë¸ ìœ í˜•: {best_type} (í‰ê·  RÂ²={best_r2:.4f})")

# --------------------------------------------------
# ê²°ê³¼ ì €ì¥
# --------------------------------------------------
global_result_path = os.path.join(SUMMARY_DIR, "RF_global_best_model.csv")
pd.DataFrame({
    "ëª¨ë¸ìœ í˜•": ["Base", "BE", "Tuned"],
    "í‰ê· _R2": [avg_base, avg_be, avg_tuned],
    "ì„ íƒëª¨ë¸": ["âœ…" if m == best_type else "" for m in ["Base", "BE", "Tuned"]]
}).to_csv(global_result_path, index=False, encoding='utf-8-sig')

print(f"\nğŸ’¾ ì „ì²´ í‰ê·  ë¹„êµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {global_result_path}")
print(f"âœ… ëª¨ë“  ë°œì „ê¸°ì— '{best_type}' ëª¨ë¸ ìœ í˜•ì„ ê³µí†µ ì ìš©í•˜ë©´ ë©ë‹ˆë‹¤.")

# --------------------------------------------------
# ì„ íƒëœ ëª¨ë¸ ìœ í˜• ì €ì¥ (ì¶”ê°€ ë¶€ë¶„)
# --------------------------------------------------
MODEL_INFO_DIR = os.path.join(BASE_DIR, "outputs/models/analysis")
os.makedirs(MODEL_INFO_DIR, exist_ok=True)

best_model_info = {
    "selected_model_type": best_type,
    "average_R2": best_r2,
    "average_scores": {
        "Base": avg_base,
        "BE": avg_be,
        "Tuned": avg_tuned
    }
}

best_model_info_path = os.path.join(MODEL_INFO_DIR, "best_RF_model_type.json")
with open(best_model_info_path, "w", encoding="utf-8") as f:
    json.dump(best_model_info, f, ensure_ascii=False, indent=2)

print(f"ğŸ§¾ ì„ íƒëœ ëª¨ë¸ ìœ í˜• ì •ë³´ ì €ì¥ ì™„ë£Œ â†’ {best_model_info_path}")
print("ğŸ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
