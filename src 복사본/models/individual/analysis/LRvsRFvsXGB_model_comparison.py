# ==============================================================
# âœ… Linear Regression vs Random Forest vs XGBoost ì„±ëŠ¥ ë¹„êµ + ê²°ê³¼ ì €ì¥
# ==============================================================

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import os
import warnings
warnings.filterwarnings("ignore")

# --------------------------------------------------------------
# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì •
# --------------------------------------------------------------
BASE_DIR = "/Users/parkhyeji/Desktop/PV"
DATA_PATH = os.path.join(BASE_DIR, "data/outliers_removed/ì´ìƒì¹˜ì œê±°_ë°ì´í„°.csv")
RESULT_DIR = os.path.join(BASE_DIR, "src/models/individual/analysis")

os.makedirs(RESULT_DIR, exist_ok=True)
RESULT_PATH = os.path.join(
    RESULT_DIR, "LRvsRFvsXGB_model_performance_comparison.csv")

# --------------------------------------------------------------
# 2ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# --------------------------------------------------------------
df = pd.read_csv(DATA_PATH, encoding='utf-8-sig')

# ë°œì „ëŸ‰ 0 ì œê±°
df = df[df['ë°œì „ëŸ‰(MWh)'] != 0].copy()

# ë…ë¦½ë³€ìˆ˜(X), ì¢…ì†ë³€ìˆ˜(y)
X = df[['ì„¤ë¹„ìš©ëŸ‰(MW)', 'í‰ê· ê¸°ì˜¨', 'í‰ê· ìŠµë„', 'ì´ê°•ìˆ˜ëŸ‰', 'ì´ì ì„¤ëŸ‰',
        'í‰ê· í’ì†', 'ì¼ì¡°ì‹œê°„', 'ì¼ì‚¬ëŸ‰', 'í‰ê· ìš´ëŸ‰']]
y = df['ë°œì „ëŸ‰(MWh)']

# --------------------------------------------------------------
# 3ï¸âƒ£ í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
# --------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

# --------------------------------------------------------------
# 4ï¸âƒ£ ëª¨ë¸ë³„ í•™ìŠµ ë° ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
# --------------------------------------------------------------


def evaluate_model(model, name):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    return {'ëª¨ë¸': name, 'RÂ²': r2, 'RMSE': rmse, 'MAE': mae}


# --------------------------------------------------------------
# 5ï¸âƒ£ ëª¨ë¸ë³„ í‰ê°€
# --------------------------------------------------------------
models = [
    (LinearRegression(), "Linear Regression"),
    (RandomForestRegressor(n_estimators=200,
     random_state=42, n_jobs=-1), "Random Forest"),
    (XGBRegressor(n_estimators=300, learning_rate=0.05,
     max_depth=6, random_state=42, n_jobs=-1), "XGBoost")
]

results = []
for model, name in models:
    print(f"ğŸš€ {name} í•™ìŠµ ì¤‘...")
    result = evaluate_model(model, name)
    results.append(result)

# --------------------------------------------------------------
# 6ï¸âƒ£ ê²°ê³¼ ë¹„êµ DataFrame ìƒì„±
# --------------------------------------------------------------
results_df = pd.DataFrame(results)

# --------------------------------------------------------------
# 7ï¸âƒ£ ìš°ìˆ˜ ëª¨ë¸ ì„ íƒ (RÂ² ê¸°ì¤€)
# --------------------------------------------------------------
best_row = results_df.loc[results_df['RÂ²'].idxmax()]
best_model_name = best_row['ëª¨ë¸']
best_r2 = best_row['RÂ²']

# ìš°ìˆ˜ëª¨ë¸ í‘œì‹œ
results_df['ìš°ìˆ˜ëª¨ë¸'] = ['âœ…' if m ==
                      best_model_name else '' for m in results_df['ëª¨ë¸']]

# --------------------------------------------------------------
# 8ï¸âƒ£ ê²°ê³¼ ì €ì¥
# --------------------------------------------------------------
results_df.to_csv(RESULT_PATH, index=False, encoding='utf-8-sig')

print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
print(results_df)
print("-" * 60)
print(f"ğŸ† ìµœì¢… ì„ íƒëœ ìš°ìˆ˜ ëª¨ë¸: {best_model_name} (RÂ²={best_r2:.4f})")
print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {RESULT_PATH}")
