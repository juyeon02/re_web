"""
ğŸŒŸ XGBoost ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ (ë°œì „ê¸°ë³„)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â‘  ë°œì „ê¸°ë³„ XGBoost í•™ìŠµ
â‘¡ ë³€ìˆ˜ ì¤‘ìš”ë„ ê³„ì‚° ë° ì‹œê°í™”
â‘¢ ì„±ëŠ¥í‰ê°€ ê²°ê³¼ + ì¤‘ìš”ë„ CSV/PNG + ëª¨ë¸ ì €ì¥
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import seaborn as sns
from src.utils.model_utils import save_model

# macOS í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# --------------------------------------------------
BASE_DIR = "/Users/parkhyeji/Desktop/PV"
DATA_PATH = os.path.join(BASE_DIR, "data/outliers_removed/ì´ìƒì¹˜ì œê±°_ë°ì´í„°.csv")

RESULT_DIR = os.path.join(BASE_DIR, "src/models/individual/xgboost/results/feature_importance")
PLOT_DIR = os.path.join(BASE_DIR, "src/models/individual/xgboost/plots/feature_importance")
MODEL_DIR = os.path.join(BASE_DIR, "outputs/models/individual/XGB/feature_importance")

os.makedirs(RESULT_DIR, exist_ok=True)
os.makedirs(PLOT_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

# --------------------------------------------------
df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
df = df[df["ë°œì „ëŸ‰(MWh)"] != 0].copy()

results = []
for gen_name, group in df.groupby("ë°œì „ê¸°ëª…"):
    if len(group) < 30:
        continue

    print(f"\nğŸ”¹ {gen_name} - ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ ì¤‘...")

    X = group[['ì„¤ë¹„ìš©ëŸ‰(MW)', 'í‰ê· ê¸°ì˜¨', 'í‰ê· ìŠµë„', 'ì´ê°•ìˆ˜ëŸ‰', 'ì´ì ì„¤ëŸ‰',
               'í‰ê· í’ì†', 'ì¼ì¡°ì‹œê°„', 'ì¼ì‚¬ëŸ‰', 'í‰ê· ìš´ëŸ‰']]
    y = group['ë°œì „ëŸ‰(MWh)']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = XGBRegressor(
        n_estimators=400, learning_rate=0.05, max_depth=6,
        subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1
    )
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # ì„±ëŠ¥ì§€í‘œ
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)

    results.append({"ë°œì „ê¸°ëª…": gen_name, "R2": r2, "RMSE": rmse, "MAE": mae})

    # ë³€ìˆ˜ ì¤‘ìš”ë„ ì €ì¥ ë° ì‹œê°í™”
    fi = pd.DataFrame({
        "ë³€ìˆ˜ëª…": X.columns,
        "ì¤‘ìš”ë„": model.feature_importances_
    }).sort_values("ì¤‘ìš”ë„", ascending=False)

    fi.to_csv(os.path.join(RESULT_DIR, f"{gen_name}_feature_importance.csv"),
              index=False, encoding="utf-8-sig")

    plt.figure(figsize=(7,4))
    sns.barplot(x="ì¤‘ìš”ë„", y="ë³€ìˆ˜ëª…", data=fi, palette="viridis")
    plt.title(f"ğŸŒŸ {gen_name} - ë³€ìˆ˜ ì¤‘ìš”ë„ (XGBoost)")
    plt.tight_layout()
    plt.savefig(os.path.join(PLOT_DIR, f"{gen_name}_ë³€ìˆ˜ì¤‘ìš”ë„.png"), bbox_inches="tight")
    plt.close()

    # ëª¨ë¸ ì €ì¥
    model_name = f"{gen_name}_XGB_feature_importance"
    save_model(model, model_name, output_dir=MODEL_DIR)

# í†µí•© ê²°ê³¼ ì €ì¥
pd.DataFrame(results).to_csv(os.path.join(RESULT_DIR, "XGB_feature_importance_ê²°ê³¼.csv"),
                             index=False, encoding="utf-8-sig")
print("âœ… ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ!")
