# -*- coding: utf-8 -*-
"""
ğŸŒ XGBoost ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (ë°œì „ê¸°ë³„ ì™„ì „íŒ + ëª¨ë¸ ì €ì¥)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â‘  ë°œì „ê¸°ë³„ XGBoost ëª¨ë¸ í•™ìŠµ
â‘¡ ì„±ëŠ¥ í‰ê°€ (RÂ², RMSE, MAE, MAPE, NRMSE)
â‘¢ Feature Importance ë¶„ì„
â‘£ ì‹¤ì œ vs ì˜ˆì¸¡ + ì”ì°¨ ì‹œê°í™”
â‘¤ ëª¨ë¸(.pkl) ë° ê²°ê³¼ CSV/PNG ì €ì¥
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import seaborn as sns
from src.utils.model_utils import save_model

# âœ… macOS í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# --------------------------------------------------
# ğŸ”§ ê²½ë¡œ ì„¤ì •
# --------------------------------------------------
BASE_DIR = "/Users/parkhyeji/Desktop/PV"
DATA_PATH = os.path.join(BASE_DIR, "data/outliers_removed/ì´ìƒì¹˜ì œê±°_ë°ì´í„°.csv")

RESULT_DIR = os.path.join(BASE_DIR, "src/models/individual/xgboost/results/train")
PLOT_DIR = os.path.join(BASE_DIR, "src/models/individual/xgboost/plots/train")
FI_DIR = os.path.join(RESULT_DIR, "feature_importance")
MODEL_DIR = os.path.join(BASE_DIR, "outputs/models/individual/XGB/train")

os.makedirs(RESULT_DIR, exist_ok=True)
os.makedirs(PLOT_DIR, exist_ok=True)
os.makedirs(FI_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

# --------------------------------------------------
# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# --------------------------------------------------
df = pd.read_csv(DATA_PATH, encoding="utf-8-sig")
df = df[df["ë°œì „ëŸ‰(MWh)"] != 0].copy()

# --------------------------------------------------
# 2ï¸âƒ£ ë°œì „ê¸°ë³„ ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------
results = []
feature_importances = []

for gen_name, group in df.groupby("ë°œì „ê¸°ëª…"):
    if len(group) < 30:
        print(f"âš ï¸ {gen_name}: ë°ì´í„° ë¶€ì¡± â†’ ê±´ë„ˆëœ€ ({len(group)}í–‰)")
        continue

    print(f"\nğŸ”¹ {gen_name} ëª¨ë¸ í•™ìŠµ ì¤‘...")

    # âœ… ì…ë ¥ ë³€ìˆ˜ (X), íƒ€ê¹ƒ ë³€ìˆ˜ (y)
    X = group[[
        'ì„¤ë¹„ìš©ëŸ‰(MW)', 'í‰ê· ê¸°ì˜¨', 'í‰ê· ìŠµë„', 'ì´ê°•ìˆ˜ëŸ‰', 'ì´ì ì„¤ëŸ‰',
        'í‰ê· í’ì†', 'ì¼ì¡°ì‹œê°„', 'ì¼ì‚¬ëŸ‰', 'í‰ê· ìš´ëŸ‰'
    ]]
    y = group['ë°œì „ëŸ‰(MWh)']

    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # --------------------------------------------------
    # 3ï¸âƒ£ XGBoost ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
    # --------------------------------------------------
    model = XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # --------------------------------------------------
    # 4ï¸âƒ£ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    # --------------------------------------------------
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test.replace(0, np.nan))) * 100
    nrmse = rmse / y_test.mean()

    results.append({
        "ë°œì „ê¸°ëª…": gen_name,
        "R2": r2,
        "RMSE": rmse,
        "MAE": mae,
        "MAPE(%)": mape,
        "NRMSE": nrmse,
        "ë°ì´í„°ìˆ˜": len(group)
    })

    # --------------------------------------------------
    # 5ï¸âƒ£ Feature Importance ì €ì¥
    # --------------------------------------------------
    fi = pd.DataFrame({
        "ë³€ìˆ˜ëª…": X.columns,
        "ì¤‘ìš”ë„": model.feature_importances_
    }).sort_values("ì¤‘ìš”ë„", ascending=False)
    fi["ë°œì „ê¸°ëª…"] = gen_name
    feature_importances.append(fi)

    fi_path = os.path.join(FI_DIR, f"{gen_name}_feature_importance.csv")
    fi.to_csv(fi_path, index=False, encoding="utf-8-sig")

    # --------------------------------------------------
    # 6ï¸âƒ£ ëª¨ë¸ ì €ì¥ (.pkl)
    # --------------------------------------------------
    model_name = f"{gen_name}_XGB_model"
    save_model(model, model_name, output_dir=MODEL_DIR)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {os.path.join(MODEL_DIR, model_name)}.pkl")

    # --------------------------------------------------
    # 7ï¸âƒ£ ì‹œê°í™”: (1) ì‹¤ì œ vs ì˜ˆì¸¡
    # --------------------------------------------------
    plt.figure(figsize=(6,6))
    sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
    sns.lineplot(x=y_test, y=y_test, color='red', label='y=x')
    plt.xlabel("ì‹¤ì œ ë°œì „ëŸ‰(MWh)")
    plt.ylabel("ì˜ˆì¸¡ ë°œì „ëŸ‰(MWh)")
    plt.title(f"ğŸ“ˆ {gen_name} - ì‹¤ì œ vs ì˜ˆì¸¡ (XGBoost)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()

    plot_path1 = os.path.join(PLOT_DIR, f"{gen_name}_ì‹¤ì œvsì˜ˆì¸¡.png")
    plt.savefig(plot_path1, bbox_inches="tight")
    plt.close()

    # --------------------------------------------------
    # 7ï¸âƒ£ ì‹œê°í™”: (2) ì”ì°¨(residual) í”Œë¡¯
    # --------------------------------------------------
    residuals = y_test - y_pred
    plt.figure(figsize=(6,4))
    sns.histplot(residuals, bins=20, kde=True)
    plt.title(f"ğŸ“Š {gen_name} - ì”ì°¨ ë¶„í¬ (XGBoost)")
    plt.xlabel("ì”ì°¨(ì‹¤ì œ - ì˜ˆì¸¡)")
    plt.tight_layout()

    plot_path2 = os.path.join(PLOT_DIR, f"{gen_name}_ì”ì°¨ë¶„í¬.png")
    plt.savefig(plot_path2, bbox_inches="tight")
    plt.close()

    # --------------------------------------------------
    # 7ï¸âƒ£ ì‹œê°í™”: (3) Feature Importance ë§‰ëŒ€ê·¸ë˜í”„
    # --------------------------------------------------
    plt.figure(figsize=(7,4))
    sns.barplot(x="ì¤‘ìš”ë„", y="ë³€ìˆ˜ëª…", data=fi, palette="viridis")
    plt.title(f"ğŸŒŸ {gen_name} - ë³€ìˆ˜ ì¤‘ìš”ë„ (XGBoost)")
    plt.tight_layout()

    plot_path3 = os.path.join(PLOT_DIR, f"{gen_name}_ë³€ìˆ˜ì¤‘ìš”ë„.png")
    plt.savefig(plot_path3, bbox_inches="tight")
    plt.close()

    print(f"âœ… {gen_name}: ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print(f"   â”œâ”€ ì˜ˆì¸¡ ê·¸ë˜í”„ â†’ {plot_path1}")
    print(f"   â”œâ”€ ì”ì°¨ ê·¸ë˜í”„ â†’ {plot_path2}")
    print(f"   â”œâ”€ ì¤‘ìš”ë„ ê·¸ë˜í”„ â†’ {plot_path3}")
    print(f"   â”œâ”€ ì¤‘ìš”ë„ CSV â†’ {fi_path}")
    print(f"   â””â”€ ëª¨ë¸ íŒŒì¼ â†’ {os.path.join(MODEL_DIR, model_name)}.pkl")

# --------------------------------------------------
# 8ï¸âƒ£ í†µí•© ê²°ê³¼ ì €ì¥
# --------------------------------------------------
result_df = pd.DataFrame(results)
fi_full = pd.concat(feature_importances, ignore_index=True)

result_path = os.path.join(RESULT_DIR, "XGB_ë°œì „ê¸°ë³„_ì„±ëŠ¥í‰ê°€ê²°ê³¼.csv")
fi_path_full = os.path.join(FI_DIR, "XGB_ì „ì²´_ë³€ìˆ˜ì¤‘ìš”ë„.csv")

result_df.to_csv(result_path, index=False, encoding="utf-8-sig")
fi_full.to_csv(fi_path_full, index=False, encoding="utf-8-sig")

print("\nâœ… ëª¨ë“  ë°œì „ê¸° XGBoost í•™ìŠµ ë° ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
print(f"ğŸ“ ì„±ëŠ¥í‰ê°€ ê²°ê³¼: {result_path}")
print(f"ğŸ“ ì „ì²´ ë³€ìˆ˜ ì¤‘ìš”ë„: {fi_path_full}")
print(f"ğŸ“ ëª¨ë¸ ì €ì¥ í´ë”: {MODEL_DIR}")
